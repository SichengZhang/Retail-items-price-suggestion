{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a416253190/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Dropout, Dense, BatchNormalization, Activation, concatenate, GRU, Embedding, Flatten, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(758065, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>mlb cincinnati reds t shirt size xl</td>\n",
       "      <td>3</td>\n",
       "      <td>Men/Tops/T-shirts</td>\n",
       "      <td>4786</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>no description yet</td>\n",
       "      <td>554</td>\n",
       "      <td>859</td>\n",
       "      <td>827</td>\n",
       "      <td>950</td>\n",
       "      <td>950</td>\n",
       "      <td>-0.369464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ava-viv blouse</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Tops &amp; Blouses/Blouse</td>\n",
       "      <td>4180</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>adorable top with a hint of lace and a key hol...</td>\n",
       "      <td>934</td>\n",
       "      <td>860</td>\n",
       "      <td>104</td>\n",
       "      <td>950</td>\n",
       "      <td>950</td>\n",
       "      <td>-0.369464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>24k gold plated rose</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Jewelry/Necklaces</td>\n",
       "      <td>4786</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>complete with certificate of authenticity</td>\n",
       "      <td>934</td>\n",
       "      <td>480</td>\n",
       "      <td>584</td>\n",
       "      <td>950</td>\n",
       "      <td>950</td>\n",
       "      <td>0.000978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                 name  item_condition_id  \\\n",
       "0      0  mlb cincinnati reds t shirt size xl                  3   \n",
       "1      1                       ava-viv blouse                  1   \n",
       "2      2                 24k gold plated rose                  1   \n",
       "\n",
       "                 category_name  brand_name  price  shipping  \\\n",
       "0            Men/Tops/T-shirts        4786   10.0         1   \n",
       "1  Women/Tops & Blouses/Blouse        4180   10.0         1   \n",
       "2      Women/Jewelry/Necklaces        4786   44.0         0   \n",
       "\n",
       "                                    item_description  cat1  cat2  cat3  cat4  \\\n",
       "0                                 no description yet   554   859   827   950   \n",
       "1  adorable top with a hint of lace and a key hol...   934   860   104   950   \n",
       "2          complete with certificate of authenticity   934   480   584   950   \n",
       "\n",
       "   cat5    target  \n",
       "0   950 -0.369464  \n",
       "1   950 -0.369464  \n",
       "2   950  0.000978  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"/mnt/disks/~/clean.csv\")\n",
    "cloth = train[(train.cat1==554)|(train.cat1==934)]\n",
    "cloth = cloth.reset_index()\n",
    "print(cloth.shape)\n",
    "cloth.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words\n",
    "Bag of Words is a model that takes the input text as a set of words regardless of the order, grammer, etc.\n",
    "We stack the whole text and make a dictionary. \n",
    "Each word is indexed by a unique number. \n",
    "And text are transformed into frequency of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "dic = np.hstack([cloth.item_description.str.lower(), cloth.name.str.lower()])\n",
    "token = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\\t\\n', lower=True, split=' ')\n",
    "token.fit_on_texts(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(758065,)\n",
      "(758065,)\n"
     ]
    }
   ],
   "source": [
    "# Transform to sequence\n",
    "cloth[\"seq_item_description\"] = token.texts_to_sequences(cloth.item_description.str.lower())\n",
    "cloth[\"seq_name\"] = token.texts_to_sequences(cloth.name.str.lower())\n",
    "\n",
    "print(cloth[\"seq_item_description\"].shape)\n",
    "print(cloth[\"seq_name\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum length of 'name' is 13 \n",
      "Maximum length of 'item description' is 212 \n"
     ]
    }
   ],
   "source": [
    "# Sequence variables\n",
    "max_name_seq = np.max([np.max(cloth.seq_name.apply(lambda x: len(x)))])\n",
    "max_seq_item_description = np.max([np.max(cloth.seq_item_description.apply(lambda x: len(x)))])\n",
    "print(\"Maximum length of 'name' is %d \" % max_name_seq)\n",
    "print(\"Maximum length of 'item description' is %d \" % max_seq_item_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a416253190/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:4: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n"
     ]
    }
   ],
   "source": [
    "#SCALE target variable\n",
    "cloth[\"target\"] = np.log(cloth.price+1)\n",
    "target_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "cloth[\"target\"] = target_scaler.fit_transform(cloth.target.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Maximum values\n",
    "# Base on the histograms, we select the next lengths\n",
    "MAX_NAME_SEQ = 10\n",
    "MAX_ITEM_DESC_SEQ = 100\n",
    "MAX_TEXT = np.max([np.max(cloth.seq_name.max()), \\\n",
    "                   np.max(cloth.seq_item_description.max())])+2\n",
    "MAX_CATEGORY = np.max([np.max(cloth.cat1.max()), \\\n",
    "                       np.max(cloth.cat2.max()), \\\n",
    "                       np.max(cloth.cat3.max())])+3\n",
    "MAX_BRAND = np.max([cloth.brand_name.max()])+1\n",
    "MAX_CONDITION = np.max([cloth.item_condition_id.max()])+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122373"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750484, 16)\n",
      "(7581, 16)\n"
     ]
    }
   ],
   "source": [
    "# EXTRACT DEVELOPTMENT TEST\n",
    "dtrain, dvalid = train_test_split(cloth, random_state=123, train_size=0.99)\n",
    "print(dtrain.shape)\n",
    "print(dvalid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "def get_keras_data(dataset):\n",
    "    X = {\n",
    "        'name': pad_sequences(dataset.seq_name, maxlen=MAX_NAME_SEQ)\n",
    "        ,'item_desc': pad_sequences(dataset.seq_item_description, maxlen=MAX_ITEM_DESC_SEQ)\n",
    "        ,'brand_name': np.array(dataset.brand_name)\n",
    "        ,'cat1': np.array(dataset.cat1)\n",
    "        ,'cat2': np.array(dataset.cat2)\n",
    "        ,'cat3': np.array(dataset.cat3)\n",
    "        ,'item_condition': np.array(dataset.item_condition_id)\n",
    "        ,'num_vars': np.array(dataset[[\"shipping\"]])\n",
    "    }\n",
    "    return X\n",
    "\n",
    "X_train = get_keras_data(dtrain)\n",
    "X_valid = get_keras_data(dvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "brand_name (InputLayer)         (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cat1 (InputLayer)               (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cat2 (InputLayer)               (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cat3 (InputLayer)               (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_condition (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_desc (InputLayer)          (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "name (InputLayer)               (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 10)        48100       brand_name[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 1, 10)        9440        cat1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 1, 10)        9440        cat2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 1, 10)        9440        cat3[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 1, 5)         30          item_condition[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 100, 50)      6118650     item_desc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 10, 50)       6118650     name[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 10)           0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 10)           0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 10)           0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 10)           0           embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 5)            0           embedding_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     (None, 16)           3216        embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "gru_2 (GRU)                     (None, 8)            1416        embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "num_vars (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 70)           0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "                                                                 flatten_5[0][0]                  \n",
      "                                                                 gru_1[0][0]                      \n",
      "                                                                 gru_2[0][0]                      \n",
      "                                                                 num_vars[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          9088        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           8256        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            65          dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 12,335,791\n",
      "Trainable params: 12,335,791\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Neural Network \n",
    "def get_callbacks(filepath, patience=2):\n",
    "    es = EarlyStopping('val_loss', patience=patience, mode=\"min\")\n",
    "    msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "    return [es, msave]\n",
    "\n",
    "def rmsle_cust(y_true, y_pred):\n",
    "    first_log = K.log(K.clip(y_pred, K.epsilon(), None) + 1.)\n",
    "    second_log = K.log(K.clip(y_true, K.epsilon(), None) + 1.)\n",
    "    return K.sqrt(K.mean(K.square(first_log - second_log), axis=-1))\n",
    "\n",
    "def get_model():\n",
    "\n",
    "    # hyper parameters\n",
    "    dr_r = 0.1\n",
    "    \n",
    "    # Inputs\n",
    "    name = Input(shape=[X_train[\"name\"].shape[1]], name=\"name\")\n",
    "    item_desc = Input(shape=[X_train[\"item_desc\"].shape[1]], name=\"item_desc\")\n",
    "    brand_name = Input(shape=[1], name=\"brand_name\")\n",
    "    cat1 = Input(shape=[1], name=\"cat1\")\n",
    "    cat2 = Input(shape=[1], name=\"cat2\")\n",
    "    cat3 = Input(shape=[1], name=\"cat3\")\n",
    "    item_condition = Input(shape=[1], name=\"item_condition\")\n",
    "    num_vars = Input(shape=[X_train[\"num_vars\"].shape[1]], name=\"num_vars\")\n",
    "    \n",
    "    # Embeddings layers\n",
    "    emb_name = Embedding(MAX_TEXT, 50)(name)\n",
    "    emb_item_desc = Embedding(MAX_TEXT, 50)(item_desc)\n",
    "    emb_brand_name = Embedding(MAX_BRAND, 10)(brand_name)\n",
    "    emb_cat1 = Embedding(MAX_CATEGORY, 10)(cat1)\n",
    "    emb_cat2 = Embedding(MAX_CATEGORY, 10)(cat2)\n",
    "    emb_cat3 = Embedding(MAX_CATEGORY, 10)(cat3)\n",
    "    emb_item_condition = Embedding(MAX_CONDITION, 5)(item_condition)\n",
    "    \n",
    "    # rnn layer\n",
    "    rnn_layer1 = GRU(16) (emb_item_desc)\n",
    "    rnn_layer2 = GRU(8) (emb_name)\n",
    "    \n",
    "    # main layer\n",
    "    main_l = concatenate([\n",
    "        Flatten() (emb_brand_name)\n",
    "        , Flatten() (emb_cat1)\n",
    "        , Flatten() (emb_cat2)\n",
    "        , Flatten() (emb_cat3)\n",
    "        , Flatten() (emb_item_condition)\n",
    "        , rnn_layer1\n",
    "        , rnn_layer2\n",
    "        , num_vars\n",
    "    ])\n",
    "    main_l = Dropout(dr_r) (Dense(128) (main_l))\n",
    "    main_l = Dropout(dr_r) (Dense(64) (main_l))\n",
    "    \n",
    "    # output\n",
    "    output = Dense(1, activation=\"linear\") (main_l)\n",
    "    \n",
    "    # model\n",
    "    model = Model([name, item_desc, brand_name\n",
    "                   , cat1, cat2, cat3, item_condition, num_vars], output)\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mae\", rmsle_cust])\n",
    "    \n",
    "    return model\n",
    "\n",
    "    \n",
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 750484 samples, validate on 7581 samples\n",
      "Epoch 1/5\n",
      "750484/750484 [==============================] - 134s 179us/step - loss: 0.0317 - mean_absolute_error: 0.1354 - rmsle_cust: 0.0195 - val_loss: 0.0178 - val_mean_absolute_error: 0.1010 - val_rmsle_cust: 0.0155\n",
      "Epoch 2/5\n",
      "750484/750484 [==============================] - 143s 190us/step - loss: 0.0179 - mean_absolute_error: 0.1010 - rmsle_cust: 0.0161 - val_loss: 0.0148 - val_mean_absolute_error: 0.0913 - val_rmsle_cust: 0.0143\n",
      "Epoch 3/5\n",
      "750484/750484 [==============================] - 151s 201us/step - loss: 0.0153 - mean_absolute_error: 0.0934 - rmsle_cust: 0.0149 - val_loss: 0.0141 - val_mean_absolute_error: 0.0889 - val_rmsle_cust: 0.0138\n",
      "Epoch 4/5\n",
      "750484/750484 [==============================] - 147s 196us/step - loss: 0.0139 - mean_absolute_error: 0.0889 - rmsle_cust: 0.0142 - val_loss: 0.0137 - val_mean_absolute_error: 0.0877 - val_rmsle_cust: 0.0137\n",
      "Epoch 5/5\n",
      "750484/750484 [==============================] - 143s 191us/step - loss: 0.0129 - mean_absolute_error: 0.0856 - rmsle_cust: 0.0136 - val_loss: 0.0136 - val_mean_absolute_error: 0.0876 - val_rmsle_cust: 0.0137\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f363a89d6d8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 20000\n",
    "epochs = 5\n",
    "\n",
    "model = get_model()\n",
    "model.fit(X_train, dtrain.target, epochs=epochs, batch_size=BATCH_SIZE\n",
    "          , validation_data=(X_valid, dvalid.target)\n",
    "          , verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE of testing:  0.46271456418866197\n"
     ]
    }
   ],
   "source": [
    "def rmsle(y, y_pred):\n",
    "    assert len(y) == len(y_pred)\n",
    "    to_sum = [(math.log(y_pred[i] + 1) - math.log(y[i] + 1)) ** 2.0 for i,pred in enumerate(y_pred)]\n",
    "    return (sum(to_sum) * (1.0/len(y))) ** 0.5\n",
    "# Source: https://www.kaggle.com/marknagelberg/rmsle-function\n",
    "\n",
    "val_preds = model.predict(X_valid)\n",
    "val_preds = target_scaler.inverse_transform(val_preds)\n",
    "val_preds = np.exp(val_preds)+1\n",
    "\n",
    "y_true = np.array(dvalid.price.values)\n",
    "y_pred = val_preds[:,0]\n",
    "v_rmsle = rmsle(y_true, y_pred)\n",
    "\n",
    "# print(\"RMSLE of training: \", score_train)\n",
    "print(\"RMSLE of testing: \", v_rmsle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 750484 samples, validate on 7581 samples\n",
      "Epoch 1/10\n",
      "750484/750484 [==============================] - 152s 202us/step - loss: 0.0241 - mean_absolute_error: 0.1172 - rmsle_cust: 0.0177 - val_loss: 0.0151 - val_mean_absolute_error: 0.0926 - val_rmsle_cust: 0.0144\n",
      "Epoch 2/10\n",
      "750484/750484 [==============================] - 145s 193us/step - loss: 0.0149 - mean_absolute_error: 0.0920 - rmsle_cust: 0.0148 - val_loss: 0.0138 - val_mean_absolute_error: 0.0887 - val_rmsle_cust: 0.0138\n",
      "Epoch 3/10\n",
      "750484/750484 [==============================] - 145s 193us/step - loss: 0.0131 - mean_absolute_error: 0.0862 - rmsle_cust: 0.0138 - val_loss: 0.0132 - val_mean_absolute_error: 0.0864 - val_rmsle_cust: 0.0136\n",
      "Epoch 4/10\n",
      "750484/750484 [==============================] - 142s 189us/step - loss: 0.0122 - mean_absolute_error: 0.0829 - rmsle_cust: 0.0132 - val_loss: 0.0131 - val_mean_absolute_error: 0.0856 - val_rmsle_cust: 0.0134\n",
      "Epoch 5/10\n",
      "750484/750484 [==============================] - 141s 188us/step - loss: 0.0116 - mean_absolute_error: 0.0807 - rmsle_cust: 0.0128 - val_loss: 0.0131 - val_mean_absolute_error: 0.0859 - val_rmsle_cust: 0.0134\n",
      "Epoch 6/10\n",
      "750484/750484 [==============================] - 142s 189us/step - loss: 0.0112 - mean_absolute_error: 0.0790 - rmsle_cust: 0.0124 - val_loss: 0.0131 - val_mean_absolute_error: 0.0857 - val_rmsle_cust: 0.0133\n",
      "Epoch 7/10\n",
      "750484/750484 [==============================] - 142s 189us/step - loss: 0.0108 - mean_absolute_error: 0.0777 - rmsle_cust: 0.0121 - val_loss: 0.0131 - val_mean_absolute_error: 0.0858 - val_rmsle_cust: 0.0134\n",
      "Epoch 8/10\n",
      "750484/750484 [==============================] - 143s 191us/step - loss: 0.0105 - mean_absolute_error: 0.0764 - rmsle_cust: 0.0119 - val_loss: 0.0135 - val_mean_absolute_error: 0.0874 - val_rmsle_cust: 0.0135\n",
      "Epoch 9/10\n",
      "750484/750484 [==============================] - 143s 190us/step - loss: 0.0103 - mean_absolute_error: 0.0754 - rmsle_cust: 0.0117 - val_loss: 0.0131 - val_mean_absolute_error: 0.0857 - val_rmsle_cust: 0.0135\n",
      "Epoch 10/10\n",
      "750484/750484 [==============================] - 145s 193us/step - loss: 0.0100 - mean_absolute_error: 0.0743 - rmsle_cust: 0.0114 - val_loss: 0.0133 - val_mean_absolute_error: 0.0859 - val_rmsle_cust: 0.0134\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f36280c1a58>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 10000\n",
    "epochs = 10\n",
    "\n",
    "model2 = get_model()\n",
    "model2.fit(X_train, dtrain.target, epochs=epochs, batch_size=BATCH_SIZE\n",
    "          , validation_data=(X_valid, dvalid.target)\n",
    "          , verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE of testing:  0.4406392452418835\n"
     ]
    }
   ],
   "source": [
    "def rmsle(y, y_pred):\n",
    "    assert len(y) == len(y_pred)\n",
    "    to_sum = [(math.log(y_pred[i] + 1) - math.log(y[i] + 1)) ** 2.0 for i,pred in enumerate(y_pred)]\n",
    "    return (sum(to_sum) * (1.0/len(y))) ** 0.5\n",
    "# Source: https://www.kaggle.com/marknagelberg/rmsle-function\n",
    "\n",
    "val_preds = model2.predict(X_valid)\n",
    "val_preds = target_scaler.inverse_transform(val_preds)\n",
    "val_preds = np.exp(val_preds)+1\n",
    "\n",
    "y_true = np.array(dvalid.price.values)\n",
    "y_pred = val_preds[:,0]\n",
    "v_rmsle = rmsle(y_true, y_pred)\n",
    "\n",
    "# print(\"RMSLE of training: \", score_train)\n",
    "print(\"RMSLE of testing: \", v_rmsle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save('/mnt/disks/~/model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
