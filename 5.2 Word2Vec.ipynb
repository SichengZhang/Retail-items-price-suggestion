{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Dropout, Dense, BatchNormalization, Activation, concatenate, GRU, Embedding, Flatten, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.word2vec import LineSentence\n",
    "from gensim.corpora import Dictionary, MmCorpus\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(758065, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlb cincinnati reds t shirt size xl</td>\n",
       "      <td>3</td>\n",
       "      <td>Men/Tops/T-shirts</td>\n",
       "      <td>4786</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>no description yet</td>\n",
       "      <td>554</td>\n",
       "      <td>859</td>\n",
       "      <td>827</td>\n",
       "      <td>950</td>\n",
       "      <td>950</td>\n",
       "      <td>-0.369464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ava-viv blouse</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Tops &amp; Blouses/Blouse</td>\n",
       "      <td>4180</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>adorable top with a hint of lace and a key hol...</td>\n",
       "      <td>934</td>\n",
       "      <td>860</td>\n",
       "      <td>104</td>\n",
       "      <td>950</td>\n",
       "      <td>950</td>\n",
       "      <td>-0.369464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24k gold plated rose</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Jewelry/Necklaces</td>\n",
       "      <td>4786</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>complete with certificate of authenticity</td>\n",
       "      <td>934</td>\n",
       "      <td>480</td>\n",
       "      <td>584</td>\n",
       "      <td>950</td>\n",
       "      <td>950</td>\n",
       "      <td>0.000978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  name  item_condition_id  \\\n",
       "0  mlb cincinnati reds t shirt size xl                  3   \n",
       "1                       ava-viv blouse                  1   \n",
       "2                 24k gold plated rose                  1   \n",
       "\n",
       "                 category_name  brand_name  price  shipping  \\\n",
       "0            Men/Tops/T-shirts        4786   10.0         1   \n",
       "1  Women/Tops & Blouses/Blouse        4180   10.0         1   \n",
       "2      Women/Jewelry/Necklaces        4786   44.0         0   \n",
       "\n",
       "                                    item_description  cat1  cat2  cat3  cat4  \\\n",
       "0                                 no description yet   554   859   827   950   \n",
       "1  adorable top with a hint of lace and a key hol...   934   860   104   950   \n",
       "2          complete with certificate of authenticity   934   480   584   950   \n",
       "\n",
       "   cat5    target  \n",
       "0   950 -0.369464  \n",
       "1   950 -0.369464  \n",
       "2   950  0.000978  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"/mnt/disks/~/clean.csv\")\n",
    "cloth = train[(train.cat1==554)|(train.cat1==934)]\n",
    "print(cloth.shape)\n",
    "cloth.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing\n",
    "cloth['token_name'] = [text_to_word_sequence(w) for w in cloth['name']]\n",
    "cloth['token_item_description'] = [text_to_word_sequence(w) for w in cloth['item_description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = Word2Vec(cloth['token_item_description'], size=2, window=5, min_count=5, sg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_vocabulary = [(term, voc.index, voc.count) for term, voc in word2vec.wv.vocab.items()]\n",
    "\n",
    "# sort by the term counts, so the most common terms appear first\n",
    "ordered_vocabulary = sorted(ordered_vocabulary, key=lambda x: -x[2])\n",
    "\n",
    "# unzip the terms, integer indices, and counts into separate lists\n",
    "ordered_terms, term_indices, term_counts = zip(*ordered_vocabulary)\n",
    "# create a DataFrame with the word2vec vectors as data,\n",
    "# and the terms as row labels\n",
    "word_vectors = pd.DataFrame(word2vec.wv.syn0[:], index=ordered_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>-0.639325</td>\n",
       "      <td>0.610294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size</th>\n",
       "      <td>1.067381</td>\n",
       "      <td>2.078361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>-1.818077</td>\n",
       "      <td>0.019953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>-1.723899</td>\n",
       "      <td>-0.038220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>-1.207547</td>\n",
       "      <td>0.380990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>with</th>\n",
       "      <td>0.539387</td>\n",
       "      <td>1.488129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <td>0.377334</td>\n",
       "      <td>1.562561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>-3.533791</td>\n",
       "      <td>-0.913277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>-1.602562</td>\n",
       "      <td>0.107850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>-4.997384</td>\n",
       "      <td>-1.554485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>-4.793091</td>\n",
       "      <td>-1.577189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worn</th>\n",
       "      <td>-1.167495</td>\n",
       "      <td>0.643524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>condition</th>\n",
       "      <td>-1.237120</td>\n",
       "      <td>0.652558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>on</th>\n",
       "      <td>-2.164610</td>\n",
       "      <td>-0.248253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>-6.255832</td>\n",
       "      <td>-1.958562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>-2.367826</td>\n",
       "      <td>-0.324065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>free</th>\n",
       "      <td>-4.820240</td>\n",
       "      <td>-1.441984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand</th>\n",
       "      <td>1.094785</td>\n",
       "      <td>1.913380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>black</th>\n",
       "      <td>3.797500</td>\n",
       "      <td>4.110284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>-3.924248</td>\n",
       "      <td>-1.031235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>or</th>\n",
       "      <td>-3.447134</td>\n",
       "      <td>-0.883721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>are</th>\n",
       "      <td>-2.323472</td>\n",
       "      <td>-0.254837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>but</th>\n",
       "      <td>-3.620621</td>\n",
       "      <td>-0.784101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>small</th>\n",
       "      <td>0.067320</td>\n",
       "      <td>1.208244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shipping</th>\n",
       "      <td>-6.240658</td>\n",
       "      <td>-2.064402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>you</th>\n",
       "      <td>-8.435897</td>\n",
       "      <td>-2.729651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rm</th>\n",
       "      <td>-3.383611</td>\n",
       "      <td>-0.754690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>never</th>\n",
       "      <td>-0.840364</td>\n",
       "      <td>0.660102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great</th>\n",
       "      <td>-1.384490</td>\n",
       "      <td>0.275370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this</th>\n",
       "      <td>-1.939848</td>\n",
       "      <td>-0.157788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54867</th>\n",
       "      <td>0.056378</td>\n",
       "      <td>0.404193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sauna</th>\n",
       "      <td>-0.014794</td>\n",
       "      <td>0.244061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>henleys</th>\n",
       "      <td>-0.083711</td>\n",
       "      <td>0.504098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>•unisex</th>\n",
       "      <td>-0.278692</td>\n",
       "      <td>0.271880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jail</th>\n",
       "      <td>-0.362318</td>\n",
       "      <td>0.370691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brainer</th>\n",
       "      <td>-0.421055</td>\n",
       "      <td>0.256871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0ct</th>\n",
       "      <td>-0.387330</td>\n",
       "      <td>0.339078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abboud</th>\n",
       "      <td>-0.260561</td>\n",
       "      <td>0.290680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>political</th>\n",
       "      <td>-0.182268</td>\n",
       "      <td>0.092522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pun</th>\n",
       "      <td>-0.497518</td>\n",
       "      <td>0.175566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starches</th>\n",
       "      <td>-0.504518</td>\n",
       "      <td>0.550495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>payne</th>\n",
       "      <td>-0.279326</td>\n",
       "      <td>0.358175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>piña</th>\n",
       "      <td>-0.202364</td>\n",
       "      <td>0.311871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ballerinas</th>\n",
       "      <td>-0.240031</td>\n",
       "      <td>0.287407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>graduating</th>\n",
       "      <td>-0.240566</td>\n",
       "      <td>0.356605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>•dimensions</th>\n",
       "      <td>-0.118063</td>\n",
       "      <td>0.234550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126cm</th>\n",
       "      <td>-0.269761</td>\n",
       "      <td>0.446366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>definatly</th>\n",
       "      <td>-0.205967</td>\n",
       "      <td>0.306447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blowholes</th>\n",
       "      <td>0.209616</td>\n",
       "      <td>0.290904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>free‼️</th>\n",
       "      <td>0.214155</td>\n",
       "      <td>-0.080287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phonograph</th>\n",
       "      <td>-0.321151</td>\n",
       "      <td>0.415971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vampires</th>\n",
       "      <td>-0.476042</td>\n",
       "      <td>0.208285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ransom</th>\n",
       "      <td>-0.175719</td>\n",
       "      <td>0.446057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bryn</th>\n",
       "      <td>-0.393426</td>\n",
       "      <td>0.241142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usaf</th>\n",
       "      <td>-0.047033</td>\n",
       "      <td>0.430891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>siberian</th>\n",
       "      <td>-0.137875</td>\n",
       "      <td>0.378196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14x13</th>\n",
       "      <td>-0.328309</td>\n",
       "      <td>0.355783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bogonia</th>\n",
       "      <td>-0.093158</td>\n",
       "      <td>0.301429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beaty</th>\n",
       "      <td>-0.447953</td>\n",
       "      <td>0.480514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stillness</th>\n",
       "      <td>-0.179238</td>\n",
       "      <td>0.365742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26740 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0         1\n",
       "and         -0.639325  0.610294\n",
       "size         1.067381  2.078361\n",
       "a           -1.818077  0.019953\n",
       "the         -1.723899 -0.038220\n",
       "in          -1.207547  0.380990\n",
       "with         0.539387  1.488129\n",
       "new          0.377334  1.562561\n",
       "for         -3.533791 -0.913277\n",
       "is          -1.602562  0.107850\n",
       "to          -4.997384 -1.554485\n",
       "no          -4.793091 -1.577189\n",
       "worn        -1.167495  0.643524\n",
       "condition   -1.237120  0.652558\n",
       "on          -2.164610 -0.248253\n",
       "i           -6.255832 -1.958562\n",
       "of          -2.367826 -0.324065\n",
       "free        -4.820240 -1.441984\n",
       "brand        1.094785  1.913380\n",
       "black        3.797500  4.110284\n",
       "it          -3.924248 -1.031235\n",
       "or          -3.447134 -0.883721\n",
       "are         -2.323472 -0.254837\n",
       "but         -3.620621 -0.784101\n",
       "small        0.067320  1.208244\n",
       "shipping    -6.240658 -2.064402\n",
       "you         -8.435897 -2.729651\n",
       "rm          -3.383611 -0.754690\n",
       "never       -0.840364  0.660102\n",
       "great       -1.384490  0.275370\n",
       "this        -1.939848 -0.157788\n",
       "...               ...       ...\n",
       "54867        0.056378  0.404193\n",
       "sauna       -0.014794  0.244061\n",
       "henleys     -0.083711  0.504098\n",
       "•unisex     -0.278692  0.271880\n",
       "jail        -0.362318  0.370691\n",
       "brainer     -0.421055  0.256871\n",
       "0ct         -0.387330  0.339078\n",
       "abboud      -0.260561  0.290680\n",
       "political   -0.182268  0.092522\n",
       "pun         -0.497518  0.175566\n",
       "starches    -0.504518  0.550495\n",
       "payne       -0.279326  0.358175\n",
       "piña        -0.202364  0.311871\n",
       "ballerinas  -0.240031  0.287407\n",
       "graduating  -0.240566  0.356605\n",
       "•dimensions -0.118063  0.234550\n",
       "126cm       -0.269761  0.446366\n",
       "definatly   -0.205967  0.306447\n",
       "blowholes    0.209616  0.290904\n",
       "free‼️       0.214155 -0.080287\n",
       "phonograph  -0.321151  0.415971\n",
       "vampires    -0.476042  0.208285\n",
       "ransom      -0.175719  0.446057\n",
       "bryn        -0.393426  0.241142\n",
       "usaf        -0.047033  0.430891\n",
       "siberian    -0.137875  0.378196\n",
       "14x13       -0.328309  0.355783\n",
       "bogonia     -0.093158  0.301429\n",
       "beaty       -0.447953  0.480514\n",
       "stillness   -0.179238  0.365742\n",
       "\n",
       "[26740 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloth = pd.read_csv('/mnt/disks/~/word.csv')\n",
    "cloth['token_name'] = [text_to_word_sequence(w) for w in cloth['name']]\n",
    "cloth['token_item_description'] = [text_to_word_sequence(w) for w in cloth['item_description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = np.zeros((cloth.shape[0],2))\n",
    "for i in range(cloth.shape[0]):\n",
    "    for w in cloth['token_item_description'][i]:\n",
    "        try:\n",
    "            vec[i] = vec[i] + word_vectors[word_vectors.index==w]\n",
    "        except:\n",
    "            vec[i] = vec[i] + [0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = ['missing', 'shirt', 't-shirt', 't shirt', 'pants', \\\n",
    "         'jeans', 'trousers', 'jacket', 'coat', \\\n",
    "         'sweater', 'hat', 'cap', 'dress', 'shorts', \\\n",
    "         'underwear', 'socks', 'blouse', 'shoes', 'boots']\n",
    "\n",
    "def getItem(text):\n",
    "    item = 'missing'\n",
    "    for w in items:\n",
    "        if re.search(w, text):\n",
    "            item = w\n",
    "    return item\n",
    "\n",
    "cloth['item_name'] = [getItem(text) for text in cloth['name']]\n",
    "\n",
    "item_name_le = LabelEncoder()\n",
    "item_name_le.fit(items)\n",
    "cloth.item_name = item_name_le.transform(cloth.item_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>target</th>\n",
       "      <th>token_name</th>\n",
       "      <th>token_item_description</th>\n",
       "      <th>vec1</th>\n",
       "      <th>vec2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlb cincinnati reds t shirt size xl</td>\n",
       "      <td>3</td>\n",
       "      <td>Men/Tops/T-shirts</td>\n",
       "      <td>4786</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>no description yet</td>\n",
       "      <td>554</td>\n",
       "      <td>859</td>\n",
       "      <td>827</td>\n",
       "      <td>950</td>\n",
       "      <td>950</td>\n",
       "      <td>-0.369464</td>\n",
       "      <td>[mlb, cincinnati, reds, t, shirt, size, xl]</td>\n",
       "      <td>[no, description, yet]</td>\n",
       "      <td>-28.168664</td>\n",
       "      <td>-9.071722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ava-viv blouse</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Tops &amp; Blouses/Blouse</td>\n",
       "      <td>4180</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>adorable top with a hint of lace and a key hol...</td>\n",
       "      <td>934</td>\n",
       "      <td>860</td>\n",
       "      <td>104</td>\n",
       "      <td>950</td>\n",
       "      <td>950</td>\n",
       "      <td>-0.369464</td>\n",
       "      <td>[ava, viv, blouse]</td>\n",
       "      <td>[adorable, top, with, a, hint, of, lace, and, ...</td>\n",
       "      <td>-19.729551</td>\n",
       "      <td>24.155161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24k gold plated rose</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Jewelry/Necklaces</td>\n",
       "      <td>4786</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>complete with certificate of authenticity</td>\n",
       "      <td>934</td>\n",
       "      <td>480</td>\n",
       "      <td>584</td>\n",
       "      <td>950</td>\n",
       "      <td>950</td>\n",
       "      <td>0.000978</td>\n",
       "      <td>[24k, gold, plated, rose]</td>\n",
       "      <td>[complete, with, certificate, of, authenticity]</td>\n",
       "      <td>-7.943107</td>\n",
       "      <td>0.258878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bundled items requested for ruie</td>\n",
       "      <td>3</td>\n",
       "      <td>Women/Other/Other</td>\n",
       "      <td>4786</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0</td>\n",
       "      <td>banana republic bottoms, candies skirt with ma...</td>\n",
       "      <td>934</td>\n",
       "      <td>609</td>\n",
       "      <td>609</td>\n",
       "      <td>950</td>\n",
       "      <td>950</td>\n",
       "      <td>0.076625</td>\n",
       "      <td>[bundled, items, requested, for, ruie]</td>\n",
       "      <td>[banana, republic, bottoms, candies, skirt, wi...</td>\n",
       "      <td>29.092519</td>\n",
       "      <td>39.313323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acacia pacific tides santorini top</td>\n",
       "      <td>3</td>\n",
       "      <td>Women/Swimwear/Two-Piece</td>\n",
       "      <td>79</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0</td>\n",
       "      <td>size small but straps slightly shortened to fi...</td>\n",
       "      <td>934</td>\n",
       "      <td>824</td>\n",
       "      <td>894</td>\n",
       "      <td>950</td>\n",
       "      <td>950</td>\n",
       "      <td>0.097672</td>\n",
       "      <td>[acacia, pacific, tides, santorini, top]</td>\n",
       "      <td>[size, small, but, straps, slightly, shortened...</td>\n",
       "      <td>-16.265248</td>\n",
       "      <td>6.449293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  name  item_condition_id  \\\n",
       "0  mlb cincinnati reds t shirt size xl                  3   \n",
       "1                       ava-viv blouse                  1   \n",
       "2                 24k gold plated rose                  1   \n",
       "3     bundled items requested for ruie                  3   \n",
       "4   acacia pacific tides santorini top                  3   \n",
       "\n",
       "                 category_name  brand_name  price  shipping  \\\n",
       "0            Men/Tops/T-shirts        4786   10.0         1   \n",
       "1  Women/Tops & Blouses/Blouse        4180   10.0         1   \n",
       "2      Women/Jewelry/Necklaces        4786   44.0         0   \n",
       "3            Women/Other/Other        4786   59.0         0   \n",
       "4     Women/Swimwear/Two-Piece          79   64.0         0   \n",
       "\n",
       "                                    item_description  cat1  cat2  cat3  cat4  \\\n",
       "0                                 no description yet   554   859   827   950   \n",
       "1  adorable top with a hint of lace and a key hol...   934   860   104   950   \n",
       "2          complete with certificate of authenticity   934   480   584   950   \n",
       "3  banana republic bottoms, candies skirt with ma...   934   609   609   950   \n",
       "4  size small but straps slightly shortened to fi...   934   824   894   950   \n",
       "\n",
       "   cat5    target                                   token_name  \\\n",
       "0   950 -0.369464  [mlb, cincinnati, reds, t, shirt, size, xl]   \n",
       "1   950 -0.369464                           [ava, viv, blouse]   \n",
       "2   950  0.000978                    [24k, gold, plated, rose]   \n",
       "3   950  0.076625       [bundled, items, requested, for, ruie]   \n",
       "4   950  0.097672     [acacia, pacific, tides, santorini, top]   \n",
       "\n",
       "                              token_item_description       vec1       vec2  \n",
       "0                             [no, description, yet] -28.168664  -9.071722  \n",
       "1  [adorable, top, with, a, hint, of, lace, and, ... -19.729551  24.155161  \n",
       "2    [complete, with, certificate, of, authenticity]  -7.943107   0.258878  \n",
       "3  [banana, republic, bottoms, candies, skirt, wi...  29.092519  39.313323  \n",
       "4  [size, small, but, straps, slightly, shortened... -16.265248   6.449293  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = pd.DataFrame(vec,columns=['vec1','vec2'])\n",
    "cloth = pd.concat([cloth,vec],axis=1)\n",
    "cloth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "X = cloth.loc[:,['item_name','item_condition_id','brand_name','shipping','cat1','cat2','cat3',\\\n",
    "                 'vec1','vec2']]\n",
    "y = cloth['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72112973372\n",
      "0.752816775926\n"
     ]
    }
   ],
   "source": [
    "def rmsle(ytrue,y):\n",
    "    return np.sqrt(mean_squared_log_error(ytrue,y))\n",
    "\n",
    "rr = RandomForestRegressor(n_estimators=500,min_samples_leaf=50,max_depth=20)\n",
    "rr.fit(X_train,y_train)\n",
    "\n",
    "y_pred_tr = rr.predict(X_train)\n",
    "score_train = rmsle(y_train,y_pred_tr)\n",
    "\n",
    "y_pred = rr.predict(X_test)\n",
    "score_test = rmsle(y_test,y_pred)\n",
    "\n",
    "print(score_train)\n",
    "print(score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(rr, open('/mnt/disks/~/rr.sav','wb'), protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(word_vectors, open('/mnt/disks/~/wordvector.sav','wb'), protocol=2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Train-valid set\n",
    "dtrain, dvalid = train_test_split(cloth, random_state=456, train_size=0.99)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Input\n",
    "def get_keras_data(dataset):\n",
    "    X = {\n",
    "        'item_name': np.array(dataset.item_name),\n",
    "        'brand_name': np.array(dataset.brand_name),\n",
    "        'cat1': np.array(dataset.cat1),\n",
    "        'cat2': np.array(dataset.cat2),\n",
    "        'cat3': np.array(dataset.cat3),\n",
    "        'item_condition': np.array(dataset.item_condition_id),\n",
    "        'num_vars': np.array(dataset[[\"shipping\"]]),\n",
    "        'vec1': np.array(dataset.vec1),\n",
    "        'vec2': np.array(dataset.vec2)\n",
    "    }\n",
    "    return X\n",
    "\n",
    "X_train = get_keras_data(dtrain)\n",
    "X_valid = get_keras_data(dvalid)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "MAX_CATEGORY = 50000\n",
    "MAX_VEC = 122373\n",
    "\n",
    "# Neural Network \n",
    "def get_callbacks(filepath, patience=2):\n",
    "    es = EarlyStopping('val_loss', patience=patience, mode=\"min\")\n",
    "    msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "    return [es, msave]\n",
    "\n",
    "def rmsle_cust(y_true, y_pred):\n",
    "    first_log = K.log(K.clip(y_pred, K.epsilon(), None) + 1.)\n",
    "    second_log = K.log(K.clip(y_true, K.epsilon(), None) + 1.)\n",
    "    return K.sqrt(K.mean(K.square(first_log - second_log), axis=-1))\n",
    "\n",
    "def get_model():\n",
    "\n",
    "    # hyper parameters\n",
    "    dr_r = 0.1\n",
    "    \n",
    "    # Inputs\n",
    "    item_name = Input(shape=[1], name=\"item_name\")\n",
    "    brand_name = Input(shape=[1], name=\"brand_name\")\n",
    "    cat1 = Input(shape=[1], name=\"cat1\")\n",
    "    cat2 = Input(shape=[1], name=\"cat2\")\n",
    "    cat3 = Input(shape=[1], name=\"cat3\")\n",
    "    item_condition = Input(shape=[1], name=\"item_condition\")\n",
    "    num_vars = Input(shape=[X_train[\"num_vars\"].shape[1]], name=\"num_vars\")\n",
    "    vec1 = Input(shape=[1], name=\"vec1\")\n",
    "    vec2 = Input(shape=[1], name=\"vec2\")\n",
    "    \n",
    "    # Embeddings layers\n",
    "    emb_brand_name = Embedding(MAX_CATEGORY, 10)(brand_name)\n",
    "    emb_cat1 = Embedding(MAX_CATEGORY, 10)(cat1)\n",
    "    emb_cat2 = Embedding(MAX_CATEGORY, 10)(cat2)\n",
    "    emb_cat3 = Embedding(MAX_CATEGORY, 10)(cat3)\n",
    "    emb_item_condition = Embedding(MAX_CATEGORY, 5)(item_condition)\n",
    "    emb_vec1 = Embedding(MAX_VEC, 10)(vec1)\n",
    "    emb_vec2 = Embedding(MAX_VEC, 10)(vec2)\n",
    "    \n",
    "    # rnn layer\n",
    "    rnn_layer1 = GRU(16) (emb_vec1)\n",
    "    rnn_layer2 = GRU(16) (emb_vec2)\n",
    "    \n",
    "    # main layer\n",
    "    main_l = concatenate([\n",
    "        Flatten() (emb_brand_name)\n",
    "        , Flatten() (emb_cat1)\n",
    "        , Flatten() (emb_cat2)\n",
    "        , Flatten() (emb_cat3)\n",
    "        , Flatten() (emb_item_condition)\n",
    "        , rnn_layer1\n",
    "        , rnn_layer2\n",
    "        , num_vars\n",
    "    ])\n",
    "    main_l = Dropout(dr_r) (Dense(128) (main_l))\n",
    "    main_l = Dropout(dr_r) (Dense(64) (main_l))\n",
    "    \n",
    "    # output\n",
    "    output = Dense(1, activation=\"linear\") (main_l)\n",
    "    \n",
    "    # model\n",
    "    model = Model([item_name, brand_name, \\\n",
    "                   cat1, cat2, cat3, item_condition, \\\n",
    "                   num_vars, vec1, vec2], output)\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mae\", rmsle_cust])\n",
    "    \n",
    "    return model\n",
    "\n",
    "    \n",
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "BATCH_SIZE = 100\n",
    "epochs = 10\n",
    "\n",
    "model = get_model()\n",
    "model.fit(X_train, dtrain.target, epochs=epochs, batch_size=BATCH_SIZE\n",
    "          , validation_data=(X_valid, dvalid.target)\n",
    "          , verbose=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pickle\n",
    "target_scaler = pickle.load(open('/mnt/disks/~/target_scaler.sav', 'rb'))\n",
    "\n",
    "def rmsle(y, y_pred):\n",
    "    assert len(y) == len(y_pred)\n",
    "    to_sum = [(math.log(y_pred[i] + 1) - math.log(y[i] + 1)) ** 2.0 for i,pred in enumerate(y_pred)]\n",
    "    return (sum(to_sum) * (1.0/len(y))) ** 0.5\n",
    "# Source: https://www.kaggle.com/marknagelberg/rmsle-function\n",
    "\n",
    "val_preds = model.predict(X_valid)\n",
    "val_preds = target_scaler.inverse_transform(val_preds)\n",
    "val_preds = np.exp(val_preds)+1\n",
    "\n",
    "y_true = np.array(dvalid.price.values)\n",
    "y_pred = val_preds[:,0]\n",
    "v_rmsle = rmsle(y_true, y_pred)\n",
    "\n",
    "# print(\"RMSLE of training: \", score_train)\n",
    "print(\"RMSLE of testing: \", v_rmsle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
